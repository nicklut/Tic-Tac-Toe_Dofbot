{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import enum\n",
    "import math\n",
    "import numpy as np\n",
    "from Arm_Lib import Arm_Device\n",
    "import cv2\n",
    "import ipywidgets.widgets as widgets\n",
    "import os\n",
    "import glob\n",
    "import dofbot_helper as dofbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captuure and Display Image\n",
    "def captureImage():\n",
    "    for i in range(5):\n",
    "        time.sleep(0.25)\n",
    "        camera = cv2.VideoCapture(0)\n",
    "        if camera is not None:\n",
    "            ret, image = camera.read()\n",
    "            if ret:\n",
    "                return image\n",
    "\n",
    "def captureImage_new():\n",
    "    for i in range(5):\n",
    "        time.sleep(0.25)\n",
    "        camera = cv2.VideoCapture(0)\n",
    "        if camera is not None:\n",
    "            ret, image = camera.read()\n",
    "            if ret:\n",
    "                return ret, image\n",
    "                \n",
    "def displayImage(img, i):\n",
    "    iw = widgets.Image(format='jpg', width=len(img), height=len(img[0]))  #This is for displaying the image in Jupyter\n",
    "    #display(iw)\n",
    "    iw.value = bytes(cv2.imencode('.jpg',img)[1])\n",
    "    cv2.imwrite('SavedImage'+str(i)+'.jpg', img) # Need to iterate name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_joints(q, speedtime=100):\n",
    "    for jnum in range(1, q.shape[0]+1):\n",
    "        dofbot.moveJoint(jnum, q[jnum-1], speedtime)\n",
    "        time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_pictures():\n",
    "    q_initial = np.array([90, 90, 45, 0, 90, 90])\n",
    "    move_joints(q_initial, 500)\n",
    "\n",
    "    for i in range(10):\n",
    "        checkerboard_image = displayImage(captureImage(), i)\n",
    "        # Move between iteration\n",
    "        q_new = q_initial + np.array([0, 0, i*0.5, i*0.5, 0, 0])\n",
    "        move_joints(q_new, 500)\n",
    "        time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTORTION COEFFICENTS\n",
      "[[-9.85210574e-01  1.81252783e+01  1.32663929e-02 -9.23384823e-03\n",
      "  -2.37226129e+02]]\n",
      "total error: 0.06228810574739997\n",
      "OLD CAMERA MATRIX\n",
      "[[1.16694501e+03 0.00000000e+00 3.38853767e+02]\n",
      " [0.00000000e+00 1.72086858e+03 2.22837231e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "CAMERA MATRIX\n",
      "[[6.55945740e+02 0.00000000e+00 1.90471433e+02]\n",
      " [0.00000000e+00 1.09491992e+03 1.54717904e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "DISTORTION\n",
      "(0, 13, 360, 305)\n"
     ]
    }
   ],
   "source": [
    "q_initial = np.array([90, 90, 45, 0, 90, 90])\n",
    "move_joints(q_initial, 500)\n",
    "\n",
    "#take_pictures()\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((9*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:7].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('*.jpg')\n",
    "img = cv2.imread('SavedImage0.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    # Find the chess board corners\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,7), None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray,corners, (20,20), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        # Draw and display the corners\n",
    "        #cv2.drawChessboardCorners(img, (7,9), corners2, ret)\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "    \n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# Calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "print(\"DISTORTION COEFFICENTS\")\n",
    "print(dist)\n",
    "# Undistortion\n",
    "img = cv2.imread('SavedImage2.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "#print(newcameramtx)\n",
    "#cv2.imwrite('test.jpg', img)\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('calibresult.png', dst)\n",
    "\n",
    "# Re-projection error\n",
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "\n",
    "q_initial = np.array([90, 90, 45, 0, 90, 90])\n",
    "move_joints(q_initial, 500)\n",
    "print(\"OLD CAMERA MATRIX\")\n",
    "print(mtx)\n",
    "print(\"CAMERA MATRIX\")\n",
    "print(newcameramtx)\n",
    "print(\"DISTORTION\")\n",
    "print(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist():\n",
    "    ret, frame = captureImage_new()\n",
    "    #crop_img = frame[60:120, 0:160] # SEE IF THIS IS NECESSARY, MIGHT NOT BE \n",
    "    #print(\"Width:\", len(frame))       # Width of image is 680\n",
    "    #print(\"Height:\", len(frame[0]))   # Height of image is 480\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0) # Constants might need to be changed here \n",
    "    ret, thresh = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresh.copy(), 1, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Select the largest contour and find its center\n",
    "    if len(contours) > 0: \n",
    "        c = max(contours, key=cv2.contourArea)\n",
    "        M = cv2.moments(c)\n",
    "        # Get the center of each blob (not sure if this is the approach we want to take)\n",
    "        \n",
    "        #cx = int(M['m10']/M['m00'])\n",
    "        #cy = int(M['m01']/M['m00'])\n",
    "\n",
    "        #cv2.line(frame,(cx,0),(cx,720),(255,0,0),1)\n",
    "        #cv2.line(frame,(0,cy),(1280,cy),(255,0,0),1)\n",
    "\n",
    "        cv2.line(frame,(320,468),(320,478),(255,0,0),1)\n",
    "        cv2.line(frame,(300,478),(340,478),(255,0,0),1)\n",
    "        cv2.drawContours(frame, max(contours, key=cv2.contourArea), -1, (0, 255, 0), 1)\n",
    "\n",
    "        '''\n",
    "        if cx >= 120:\n",
    "            print(\"Turn Left\")\n",
    "        if cx < 120 and cx > 50:\n",
    "            print(\"On Track\")\n",
    "        if cx <= 50:\n",
    "            print(\"Turn right\")\n",
    "        '''\n",
    "    else:\n",
    "        return 0, 0\n",
    "        #print(\"I dont see the line\")\n",
    "\n",
    "\n",
    "    iw = widgets.Image(format='jpg', width=len(frame), height=len(frame[0]))\n",
    "    iw.value = bytes(cv2.imencode('.jpg',frame)[1])\n",
    "    cv2.imwrite('TEST'+'.jpg', frame)    \n",
    "\n",
    "    # Find closest point along contour \n",
    "    end_effector = np.array([320,480])\n",
    "    obstacle = max(contours, key=cv2.contourArea)\n",
    "    obstacle = np.reshape(obstacle, (obstacle.shape[0], obstacle.shape[2]))\n",
    "\n",
    "    min_dist = np.linalg.norm(obstacle[0,:]-end_effector)\n",
    "    min_val = [] \n",
    "    \n",
    "    if obstacle.shape[0] < 100:\n",
    "        return 0, 0\n",
    "    \n",
    "    for val in obstacle: \n",
    "        dist = np.linalg.norm(val-end_effector)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_val = val\n",
    "    \n",
    "    #print(obstacle.shape)\n",
    "    #print(\"The min distance is:\", min_dist)\n",
    "    #print(\"The min distance location is:\", min_val)\n",
    "    \n",
    "    return min_dist, min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def attract_goal(q, qd, k):\n",
    "    return -k*(q-qd)\n",
    "\n",
    "def repel_goal(q, eta, rho0):\n",
    "    d, val = 0, 0\n",
    "    d, val = dist()\n",
    "    if d == 0 or d > 200:\n",
    "        return np.zeros((6,))\n",
    "    else:\n",
    "        # -eta*(1/d-1/rho0)*(-1/d^2)*2*(P-c)/norm(P-c);\n",
    "        dif = np.array([3,0,0,0,0,0])\n",
    "        return dif\n",
    "\n",
    "def object_avoidance(q_prev, qf, step_size):\n",
    "    lam = 0\n",
    "    q_cur = q_prev\n",
    "    flag = 0\n",
    "    k = 2; # attractive gain\n",
    "    eta = 0.001; # repulsive gain\n",
    "    rho0 = 0.1; # buffer around obstacle where repulsive field is active\n",
    "    \n",
    "    for i in range(0, int(1/step_size)):\n",
    "        q_cur = q_prev + step_size*attract_goal(q_prev, qf, k) + repel_goal(q_prev, eta, rho0)\n",
    "        move_joints(q_cur)\n",
    "        q_prev = q_cur\n",
    "        lam += step_size\n",
    "        \n",
    "    return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_initial = np.array([90, 90, 15, 0, 90, 170])\n",
    "q_final = np.array([100, 40, 60, 40, 90, 170])\n",
    "move_joints(q_initial, 500)\n",
    "#move_joints(q_final,500)\n",
    "\n",
    "#q_new = q_initial - 0.03*(q_initial-q_final)\n",
    "#print(q_new)\n",
    "object_avoidance(q_initial, q_final, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_temp = np.array([93, 90, 15, 0, 90, 170])\n",
    "move_joints(q_temp, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn Left\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "min_dist, min_val = dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
